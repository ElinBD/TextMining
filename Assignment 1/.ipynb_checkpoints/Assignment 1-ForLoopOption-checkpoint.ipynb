{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining \n",
    "## Hand-in Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student: Elin Benja Dijkstra\n",
    "\n",
    "Studentnumber: S2696096\n",
    "\n",
    "Deadline: 20-10-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The\ttutorial\tclassifies\tbetween only\tfour\tcategories\tof\tthe\t20newsgroups\tdata\tset.\tChange\t\n",
    "your\tscript\tso\tthat\tit\taddresses all\t20\tcategories.\n",
    "DONE\n",
    "\n",
    "2. Compare\tthree\tclassifiers\ton\tthis\tmulti-class\tclassification\ttask,\tincluding\tat\tleast\tNa√Øve\tBayes. DONE\n",
    "3. Compare\tthree\ttype\tof\tfeatures for\tyour\tclassifiers:\tcounts,\ttf,\tand\ttf-idf.\n",
    "4. Look\tup\tthe\tdocumentation\tof\tthe\tCountVectorizer function\tand\texperiment\twith\tdifferent\t\n",
    "values\tfor\tthe\tfollowing\tparameters:\t\n",
    "a. lowercase\n",
    "b. stop_words\n",
    "c. analyzer\t(in\tcombination\twith\tngram_range)\n",
    "d. max_features\n",
    "5. Write\tone\tscript\tfor\trunning these\texperiments and\tprinting\tthe\tresults."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and examining the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the first assignment 1.1) we simply remove the categories = categories so we no longer get a subset but all 20 categories in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our training and testing set\n",
    "twenty_train = fetch_20newsgroups(subset='train', shuffle=True, random_state=42)\n",
    "twenty_test = fetch_20newsgroups(subset='test', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize our count vector with different features as described in assignment 1.4)\n",
    "def experiment_count_vect(lower_case_bool, stop_words, analyzer, max_features):\n",
    "    return CountVectorizer(lowercase = lower_case_bool, stop_words = stop_words, \n",
    "                                 analyzer = analyzer, max_features = max_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize our data depending on the different features for our classifiers defined in 1.3)\n",
    "def tokenize(count_vect, feature_type):\n",
    "    X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "    if feature_type == \"tf\":\n",
    "        tfidf_transformer = TfidfTransformer(use_idf=False)\n",
    "        X_train_tf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "        return X_train_tf\n",
    "    elif feature_type == \"tfidf\":\n",
    "        tfidf_transformer = TfidfTransformer()\n",
    "        X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "        return X_train_tfidf\n",
    "    else: \n",
    "        return X_train_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choose one of three classifiers: Naive Bayes, Stochastic Gradient Descent of LogisticRegression/Support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(type_classifier):\n",
    "    if type_classifier == \"Naive Bayes\":\n",
    "#         clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)\n",
    "        text_clf = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', MultinomialNB()),\n",
    "        ])\n",
    "    elif type_classifier == \"SGD\":\n",
    "        text_clf = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', SGDClassifier(loss='hinge', penalty='l2',\n",
    "                                  alpha=1e-3, random_state=42,\n",
    "                                  max_iter=5, tol=None)),\n",
    "        ])\n",
    "    elif type_classifier == \"Logistic Regression\":\n",
    "        text_clf = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', LogisticRegression(penalty='l2', multi_class = \"ovr\")),\n",
    "        ])\n",
    "        \n",
    "    elif type_classifier == \"SVM\":\n",
    "        text_clf = Pipeline([\n",
    "            ('vect', CountVectorizer()),\n",
    "            ('tfidf', TfidfTransformer()),\n",
    "            ('clf', SVC(decision_function_shape = \"ovr\")),\n",
    "        ])\n",
    "    return text_clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(text_clf):\n",
    "    docs_test = twenty_test.data\n",
    "    predicted = text_clf.predict(docs_test)\n",
    "    np.mean(predicted == twenty_test.target) \n",
    "    \n",
    "    print(metrics.classification_report(twenty_test.target, predicted,\n",
    "    target_names=twenty_test.target_names))\n",
    "    print(\"Confusion matrix: \")\n",
    "    cm = metrics.confusion_matrix(twenty_test.target, predicted)\n",
    "#     print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_experiment(lower_case, stop_words, analyzer, max_features, feature_type, classifiers):\n",
    "    count_vect = experiment_count_vect(lower_case, stop_words, analyzer, max_features)\n",
    "    tokenize(count_vect, feature_type)\n",
    "    for classifier in classifiers:\n",
    "        print(color.BOLD + '\\n Evaluation for' + str(classifier) + '\\n' + color.END)\n",
    "        text_clf = train_classifier(classifier)\n",
    "        fit = text_clf.fit(twenty_train.data, twenty_train.target)  \n",
    "        evaluate(fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters used: lowercase:False\n",
      "stop_words: None\n",
      "analyzer: char\n",
      "max_features: 1000\n",
      "feature_type: tfidf\n",
      "\u001b[1m\n",
      " Evaluation forLogistic Regression\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elind\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.74      0.77       319\n",
      "           comp.graphics       0.69      0.78      0.74       389\n",
      " comp.os.ms-windows.misc       0.76      0.75      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.72      0.72       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.83      0.74      0.78       395\n",
      "            misc.forsale       0.76      0.90      0.83       390\n",
      "               rec.autos       0.91      0.89      0.90       396\n",
      "         rec.motorcycles       0.94      0.95      0.94       398\n",
      "      rec.sport.baseball       0.87      0.93      0.90       397\n",
      "        rec.sport.hockey       0.94      0.96      0.95       399\n",
      "               sci.crypt       0.93      0.89      0.91       396\n",
      "         sci.electronics       0.76      0.78      0.77       393\n",
      "                 sci.med       0.89      0.84      0.86       396\n",
      "               sci.space       0.89      0.92      0.91       394\n",
      "  soc.religion.christian       0.79      0.93      0.85       398\n",
      "      talk.politics.guns       0.71      0.90      0.80       364\n",
      "   talk.politics.mideast       0.96      0.89      0.92       376\n",
      "      talk.politics.misc       0.79      0.58      0.67       310\n",
      "      talk.religion.misc       0.83      0.45      0.59       251\n",
      "\n",
      "                accuracy                           0.83      7532\n",
      "               macro avg       0.83      0.82      0.82      7532\n",
      "            weighted avg       0.83      0.83      0.83      7532\n",
      "\n",
      "Confusion matrix: \n",
      "\u001b[1m\n",
      " Evaluation forSGD\n",
      "\u001b[0m\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.71      0.72       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.73      0.78      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.67      0.70       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.84      0.76      0.80       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.91      0.90      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.95       398\n",
      "      rec.sport.baseball       0.88      0.90      0.89       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.84      0.96      0.90       396\n",
      "         sci.electronics       0.83      0.62      0.71       393\n",
      "                 sci.med       0.87      0.86      0.87       396\n",
      "               sci.space       0.84      0.96      0.90       394\n",
      "  soc.religion.christian       0.76      0.94      0.84       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.90      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.85      0.41      0.55       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.83      0.81      0.81      7532\n",
      "            weighted avg       0.83      0.82      0.82      7532\n",
      "\n",
      "Confusion matrix: \n",
      "\u001b[1m\n",
      " Evaluation forNaive Bayes\n",
      "\u001b[0m\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.83      0.76      0.76      7532\n",
      "            weighted avg       0.82      0.77      0.77      7532\n",
      "\n",
      "Confusion matrix: \n",
      "Parameters used: lowercase:False\n",
      "stop_words: None\n",
      "analyzer: char\n",
      "max_features: 1000\n",
      "feature_type: counts\n",
      "\u001b[1m\n",
      " Evaluation forLogistic Regression\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elind\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.74      0.77       319\n",
      "           comp.graphics       0.69      0.78      0.74       389\n",
      " comp.os.ms-windows.misc       0.76      0.75      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.72      0.72       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.83      0.74      0.78       395\n",
      "            misc.forsale       0.76      0.90      0.83       390\n",
      "               rec.autos       0.91      0.89      0.90       396\n",
      "         rec.motorcycles       0.94      0.95      0.94       398\n",
      "      rec.sport.baseball       0.87      0.93      0.90       397\n",
      "        rec.sport.hockey       0.94      0.96      0.95       399\n",
      "               sci.crypt       0.93      0.89      0.91       396\n",
      "         sci.electronics       0.76      0.78      0.77       393\n",
      "                 sci.med       0.89      0.84      0.86       396\n",
      "               sci.space       0.89      0.92      0.91       394\n",
      "  soc.religion.christian       0.79      0.93      0.85       398\n",
      "      talk.politics.guns       0.71      0.90      0.80       364\n",
      "   talk.politics.mideast       0.96      0.89      0.92       376\n",
      "      talk.politics.misc       0.79      0.58      0.67       310\n",
      "      talk.religion.misc       0.83      0.45      0.59       251\n",
      "\n",
      "                accuracy                           0.83      7532\n",
      "               macro avg       0.83      0.82      0.82      7532\n",
      "            weighted avg       0.83      0.83      0.83      7532\n",
      "\n",
      "Confusion matrix: \n",
      "\u001b[1m\n",
      " Evaluation forSGD\n",
      "\u001b[0m\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.71      0.72       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.73      0.78      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.67      0.70       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.84      0.76      0.80       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.91      0.90      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.95       398\n",
      "      rec.sport.baseball       0.88      0.90      0.89       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.84      0.96      0.90       396\n",
      "         sci.electronics       0.83      0.62      0.71       393\n",
      "                 sci.med       0.87      0.86      0.87       396\n",
      "               sci.space       0.84      0.96      0.90       394\n",
      "  soc.religion.christian       0.76      0.94      0.84       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.90      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.85      0.41      0.55       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.83      0.81      0.81      7532\n",
      "            weighted avg       0.83      0.82      0.82      7532\n",
      "\n",
      "Confusion matrix: \n",
      "\u001b[1m\n",
      " Evaluation forNaive Bayes\n",
      "\u001b[0m\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.83      0.76      0.76      7532\n",
      "            weighted avg       0.82      0.77      0.77      7532\n",
      "\n",
      "Confusion matrix: \n",
      "Parameters used: lowercase:False\n",
      "stop_words: None\n",
      "analyzer: char\n",
      "max_features: 1000\n",
      "feature_type: tf\n",
      "\u001b[1m\n",
      " Evaluation forLogistic Regression\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elind\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.74      0.77       319\n",
      "           comp.graphics       0.69      0.78      0.74       389\n",
      " comp.os.ms-windows.misc       0.76      0.75      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.73      0.72      0.72       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.83      0.74      0.78       395\n",
      "            misc.forsale       0.76      0.90      0.83       390\n",
      "               rec.autos       0.91      0.89      0.90       396\n",
      "         rec.motorcycles       0.94      0.95      0.94       398\n",
      "      rec.sport.baseball       0.87      0.93      0.90       397\n",
      "        rec.sport.hockey       0.94      0.96      0.95       399\n",
      "               sci.crypt       0.93      0.89      0.91       396\n",
      "         sci.electronics       0.76      0.78      0.77       393\n",
      "                 sci.med       0.89      0.84      0.86       396\n",
      "               sci.space       0.89      0.92      0.91       394\n",
      "  soc.religion.christian       0.79      0.93      0.85       398\n",
      "      talk.politics.guns       0.71      0.90      0.80       364\n",
      "   talk.politics.mideast       0.96      0.89      0.92       376\n",
      "      talk.politics.misc       0.79      0.58      0.67       310\n",
      "      talk.religion.misc       0.83      0.45      0.59       251\n",
      "\n",
      "                accuracy                           0.83      7532\n",
      "               macro avg       0.83      0.82      0.82      7532\n",
      "            weighted avg       0.83      0.83      0.83      7532\n",
      "\n",
      "Confusion matrix: \n",
      "\u001b[1m\n",
      " Evaluation forSGD\n",
      "\u001b[0m\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.73      0.71      0.72       319\n",
      "           comp.graphics       0.78      0.72      0.75       389\n",
      " comp.os.ms-windows.misc       0.73      0.78      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.74      0.67      0.70       392\n",
      "   comp.sys.mac.hardware       0.81      0.83      0.82       385\n",
      "          comp.windows.x       0.84      0.76      0.80       395\n",
      "            misc.forsale       0.84      0.90      0.87       390\n",
      "               rec.autos       0.91      0.90      0.90       396\n",
      "         rec.motorcycles       0.93      0.96      0.95       398\n",
      "      rec.sport.baseball       0.88      0.90      0.89       397\n",
      "        rec.sport.hockey       0.88      0.99      0.93       399\n",
      "               sci.crypt       0.84      0.96      0.90       396\n",
      "         sci.electronics       0.83      0.62      0.71       393\n",
      "                 sci.med       0.87      0.86      0.87       396\n",
      "               sci.space       0.84      0.96      0.90       394\n",
      "  soc.religion.christian       0.76      0.94      0.84       398\n",
      "      talk.politics.guns       0.70      0.92      0.80       364\n",
      "   talk.politics.mideast       0.90      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.55      0.68       310\n",
      "      talk.religion.misc       0.85      0.41      0.55       251\n",
      "\n",
      "                accuracy                           0.82      7532\n",
      "               macro avg       0.83      0.81      0.81      7532\n",
      "            weighted avg       0.83      0.82      0.82      7532\n",
      "\n",
      "Confusion matrix: \n",
      "\u001b[1m\n",
      " Evaluation forNaive Bayes\n",
      "\u001b[0m\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.80      0.52      0.63       319\n",
      "           comp.graphics       0.81      0.65      0.72       389\n",
      " comp.os.ms-windows.misc       0.82      0.65      0.73       394\n",
      "comp.sys.ibm.pc.hardware       0.67      0.78      0.72       392\n",
      "   comp.sys.mac.hardware       0.86      0.77      0.81       385\n",
      "          comp.windows.x       0.89      0.75      0.82       395\n",
      "            misc.forsale       0.93      0.69      0.80       390\n",
      "               rec.autos       0.85      0.92      0.88       396\n",
      "         rec.motorcycles       0.94      0.93      0.93       398\n",
      "      rec.sport.baseball       0.92      0.90      0.91       397\n",
      "        rec.sport.hockey       0.89      0.97      0.93       399\n",
      "               sci.crypt       0.59      0.97      0.74       396\n",
      "         sci.electronics       0.84      0.60      0.70       393\n",
      "                 sci.med       0.92      0.74      0.82       396\n",
      "               sci.space       0.84      0.89      0.87       394\n",
      "  soc.religion.christian       0.44      0.98      0.61       398\n",
      "      talk.politics.guns       0.64      0.94      0.76       364\n",
      "   talk.politics.mideast       0.93      0.91      0.92       376\n",
      "      talk.politics.misc       0.96      0.42      0.58       310\n",
      "      talk.religion.misc       0.97      0.14      0.24       251\n",
      "\n",
      "                accuracy                           0.77      7532\n",
      "               macro avg       0.83      0.76      0.76      7532\n",
      "            weighted avg       0.82      0.77      0.77      7532\n",
      "\n",
      "Confusion matrix: \n",
      "Parameters used: lowercase:False\n",
      "stop_words: None\n",
      "analyzer: char\n",
      "max_features: 10000\n",
      "feature_type: tfidf\n",
      "\u001b[1m\n",
      " Evaluation forLogistic Regression\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elind\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-1fcee9f5375a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m                           \u001b[1;34m\"\\nanalyzer: \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manalyzer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"\\nmax_features: \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m \u001b[1;34m\"\\nfeature_type: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m                           + str(feature_type))\n\u001b[1;32m----> 9\u001b[1;33m                     \u001b[0mstart_experiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlower_case\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassifiers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-c4fd4107b502>\u001b[0m in \u001b[0;36mstart_experiment\u001b[1;34m(lower_case, stop_words, analyzer, max_features, feature_type, classifiers)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBOLD\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n Evaluation for'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\n'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mtext_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mfit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtext_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtwenty_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtwenty_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m         \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    354\u001b[0m                                  self._log_message(len(self.steps) - 1)):\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'passthrough'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 356\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    357\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1549\u001b[1;33m                 sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1550\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda2\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m         epsilon, sample_weight)\n\u001b[0m\u001b[0;32m    922\u001b[0m     \u001b[1;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m     \u001b[1;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for lower_case in lower_case_set:\n",
    "    for stop_words in stop_words_set:\n",
    "        for analyzer in analyzer_set:\n",
    "            for max_features in max_features_set:\n",
    "                for feature_type in feature_type_set:\n",
    "                    print(\"Parameters used:\" + \" lowercase:\"+ str(lower_case)+ \"\\nstop_words: \"+ str(stop_words)+\n",
    "                          \"\\nanalyzer: \"+ str(analyzer)+ \"\\nmax_features: \"+ str(max_features)+ \"\\nfeature_type: \" \n",
    "                          + str(feature_type))\n",
    "                    start_experiment(lower_case, stop_words, analyzer, max_features, feature_type, classifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'lower_case': (True, False)\n",
    "    'stop_words':  ('english', None) \n",
    "    'analyzer': ['word', 'char', 'char_wb']\n",
    "    'max_features': (100, 1000, 10000)\n",
    "    'feature_type': ['counts', 'tf', 'tfidf']\n",
    "    'classifiers': ['Naive Bayes', 'SGD', 'Logistic Regression', 'SVM']      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf.best_score_\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, gs_clf.best_params_[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(gs_clf.cv_results_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
